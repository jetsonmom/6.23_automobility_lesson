{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0014a1-c433-4b19-bda4-e0e8cd1f6f5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2025.6.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "âœ… yt-dlp ì„¤ì¹˜ ì™„ë£Œ!\n",
      "ğŸ“¹ YouTube ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹œì‘...\n",
      "ğŸ”— URL: https://www.youtube.com/shorts/vQfWixBn15U\n",
      "âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ!\n",
      "ğŸ“ íŒŒì¼ í¬ê¸°: 0.9 MB\n",
      "ğŸ¯ íŒŒì¼ëª…: traffic_video.mp4\n"
     ]
    }
   ],
   "source": [
    "# YouTube ë‹¤ìš´ë¡œë“œ ë„êµ¬ ì„¤ì¹˜\n",
    "!pip install yt-dlp\n",
    "\n",
    "print(\"âœ… yt-dlp ì„¤ì¹˜ ì™„ë£Œ!\")\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# YouTube URL\n",
    "youtube_url = \"https://www.youtube.com/shorts/vQfWixBn15U\"\n",
    "\n",
    "# ì˜ìƒ ë‹¤ìš´ë¡œë“œ\n",
    "def download_video():\n",
    "    print(f\"ğŸ“¹ YouTube ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹œì‘...\")\n",
    "    print(f\"ğŸ”— URL: {youtube_url}\")\n",
    "    \n",
    "    try:\n",
    "        # yt-dlp ëª…ë ¹ì–´ ì‹¤í–‰\n",
    "        result = subprocess.run([\n",
    "            'yt-dlp', \n",
    "            '-f', 'best[height<=720]',\n",
    "            '-o', 'traffic_video.mp4',\n",
    "            youtube_url\n",
    "        ], capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ!\")\n",
    "            return 'traffic_video.mp4'\n",
    "        else:\n",
    "            print(f\"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "# ë‹¤ìš´ë¡œë“œ ì‹¤í–‰\n",
    "video_file = download_video()\n",
    "\n",
    "# íŒŒì¼ í™•ì¸\n",
    "if video_file and os.path.exists(video_file):\n",
    "    file_size = os.path.getsize(video_file) / (1024*1024)\n",
    "    print(f\"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size:.1f} MB\")\n",
    "    print(f\"ğŸ¯ íŒŒì¼ëª…: {video_file}\")\n",
    "else:\n",
    "    print(\"âŒ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bc7e59-fc51-4ffe-bed9-775127cf8aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03985d27-311d-488b-80fe-70c6f3392ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’» ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: cuda\n",
      "ğŸ¯ GPU: NVIDIA GeForce RTX 3090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# GPU ì„¤ì •\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸ’» ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}\")\n",
    "print(f\"ğŸ¯ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# TrafficCamNet ìŠ¤íƒ€ì¼ ëª¨ë¸ ë¡œë“œ\n",
    "model = detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655acace-d01d-4818-9220-918f5b6c04f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¹ ì˜ìƒ ì •ë³´:\n",
      "  í•´ìƒë„: 360 x 640\n",
      "  FPS: 30.0\n",
      "  ì´ í”„ë ˆì„: 372\n",
      "  ê¸¸ì´: 12.4ì´ˆ\n",
      "ğŸ“¹ ì˜ìƒ ì •ë³´:\n",
      "  í•´ìƒë„: 360 x 640\n",
      "  FPS: 30.0\n",
      "  ì´ í”„ë ˆì„: 372\n",
      "  ê¸¸ì´: 12.4ì´ˆ\n",
      "âœ… ë°”ìš´ë”© ë°•ìŠ¤ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "def check_video():\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        return None\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "    \n",
    "    print(f\"ğŸ“¹ ì˜ìƒ ì •ë³´:\")\n",
    "    print(f\"  í•´ìƒë„: {width} x {height}\")\n",
    "    print(f\"  FPS: {fps:.1f}\")\n",
    "    print(f\"  ì´ í”„ë ˆì„: {total_frames}\")\n",
    "    print(f\"  ê¸¸ì´: {duration:.1f}ì´ˆ\")\n",
    "    \n",
    "    cap.release()\n",
    "    return {'fps': fps, 'width': width, 'height': height, 'frames': total_frames}\n",
    "\n",
    "# ì˜ìƒ ì •ë³´ í™•ì¸\n",
    "if video_file:\n",
    "    video_info = check_video()\n",
    "\n",
    "\n",
    "def check_video():\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        return None\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps\n",
    "    \n",
    "    print(f\"ğŸ“¹ ì˜ìƒ ì •ë³´:\")\n",
    "    print(f\"  í•´ìƒë„: {width} x {height}\")\n",
    "    print(f\"  FPS: {fps:.1f}\")\n",
    "    print(f\"  ì´ í”„ë ˆì„: {total_frames}\")\n",
    "    print(f\"  ê¸¸ì´: {duration:.1f}ì´ˆ\")\n",
    "    \n",
    "    cap.release()\n",
    "    return {'fps': fps, 'width': width, 'height': height, 'frames': total_frames}\n",
    "\n",
    "# ì˜ìƒ ì •ë³´ í™•ì¸\n",
    "if video_file:\n",
    "    video_info = check_video()\n",
    "def draw_detections(frame, results):\n",
    "    annotated = frame.copy()\n",
    "    \n",
    "    # ì°¨ëŸ‰ (ë¹¨ê°„ìƒ‰)\n",
    "    for vehicle in results['vehicles']:\n",
    "        box = vehicle['box'].astype(int)\n",
    "        cv2.rectangle(annotated, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), 3)\n",
    "        label = f\"{vehicle['class_name']}: {vehicle['score']:.2f}\"\n",
    "        cv2.putText(annotated, label, (box[0], box[1]-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    # ë³´í–‰ì (íŒŒë€ìƒ‰)\n",
    "    for person in results['pedestrians']:\n",
    "        box = person['box'].astype(int)\n",
    "        cv2.rectangle(annotated, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 3)\n",
    "        label = f\"Person: {person['score']:.2f}\"\n",
    "        cv2.putText(annotated, label, (box[0], box[1]-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    \n",
    "    # êµí†µ ì¸í”„ë¼ (ì´ˆë¡ìƒ‰)\n",
    "    for infra in results['infrastructure']:\n",
    "        box = infra['box'].astype(int)\n",
    "        cv2.rectangle(annotated, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 3)\n",
    "        label = f\"{infra['class_name']}: {infra['score']:.2f}\"\n",
    "        cv2.putText(annotated, label, (box[0], box[1]-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    return annotated\n",
    "\n",
    "print(\"âœ… ë°”ìš´ë”© ë°•ìŠ¤ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b831103f-fc5b-4e66-b471-34f48c1ceba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë©”ì¸ ë¶„ì„ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "def analyze_traffic_video():\n",
    "    print(f\"\\nğŸš€ TrafficCamNet ì˜ìƒ ë¶„ì„ ì‹œì‘!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ì˜ìƒ ì—´ê¸°\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        return\n",
    "    \n",
    "    # ì˜ìƒ ì •ë³´\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # ì¶œë ¥ ì˜ìƒ ì„¤ì •\n",
    "    output_path = \"analyzed_traffic.mp4\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # í†µê³„ ë³€ìˆ˜\n",
    "    frame_count = 0\n",
    "    vehicle_counts = []\n",
    "    pedestrian_counts = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"ğŸ¯ ì´ {total_frames}í”„ë ˆì„ ë¶„ì„ ì‹œì‘...\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # RGB ë³€í™˜\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # TrafficCamNet ë¶„ì„\n",
    "        results = analyze_frame(frame_rgb, confidence_threshold=0.4)\n",
    "        \n",
    "        # í†µê³„ ìˆ˜ì§‘\n",
    "        vehicles = len(results['vehicles'])\n",
    "        pedestrians = len(results['pedestrians'])\n",
    "        infrastructure = len(results['infrastructure'])\n",
    "        \n",
    "        vehicle_counts.append(vehicles)\n",
    "        pedestrian_counts.append(pedestrians)\n",
    "        \n",
    "        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
    "        annotated_frame = draw_detections(frame, results)\n",
    "        \n",
    "        # ì •ë³´ ì˜¤ë²„ë ˆì´\n",
    "        current_time = frame_count / fps\n",
    "        info_lines = [\n",
    "            f\"Frame: {frame_count}/{total_frames}\",\n",
    "            f\"Time: {current_time:.1f}s\",\n",
    "            f\"Vehicles: {vehicles}\",\n",
    "            f\"Pedestrians: {pedestrians}\",\n",
    "            f\"Infrastructure: {infrastructure}\",\n",
    "            \"RTX 3090 Analysis\"\n",
    "        ]\n",
    "        \n",
    "        # ë°°ê²½ ë°•ìŠ¤\n",
    "        cv2.rectangle(annotated_frame, (10, 10), (300, 180), (0, 0, 0), -1)\n",
    "        \n",
    "        # ì •ë³´ í…ìŠ¤íŠ¸\n",
    "        y_pos = 35\n",
    "        for line in info_lines:\n",
    "            cv2.putText(annotated_frame, line, (20, y_pos), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            y_pos += 25\n",
    "        \n",
    "        # ì¶œë ¥ ì˜ìƒì— ì“°ê¸°\n",
    "        out.write(annotated_frame)\n",
    "        \n",
    "        # ì§„í–‰ ìƒí™© (10í”„ë ˆì„ë§ˆë‹¤)\n",
    "        if frame_count % 10 == 0:\n",
    "            progress = frame_count / total_frames * 100\n",
    "            elapsed = time.time() - start_time\n",
    "            fps_current = frame_count / elapsed if elapsed > 0 else 0\n",
    "            \n",
    "            print(f\"ì§„í–‰ë¥ : {progress:5.1f}% | \"\n",
    "                  f\"ì°¨ëŸ‰: {vehicles:2d}ëŒ€ | \"\n",
    "                  f\"ë³´í–‰ì: {pedestrians:2d}ëª… | \"\n",
    "                  f\"ì†ë„: {fps_current:5.1f} FPS\")\n",
    "    \n",
    "    # ì •ë¦¬\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    avg_fps = frame_count / total_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ğŸ¬ YouTube TrafficCamNet ë¶„ì„ ì™„ë£Œ!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.1f}ì´ˆ\")\n",
    "    print(f\"ğŸ”¥ í‰ê·  ì²˜ë¦¬ ì†ë„: {avg_fps:.1f} FPS\")\n",
    "    \n",
    "    if vehicle_counts:\n",
    "        print(f\"ğŸš— ìµœëŒ€ ì°¨ëŸ‰ ìˆ˜: {max(vehicle_counts)}ëŒ€\")\n",
    "        print(f\"ğŸš— í‰ê·  ì°¨ëŸ‰ ìˆ˜: {sum(vehicle_counts)/len(vehicle_counts):.1f}ëŒ€\")\n",
    "    \n",
    "    if pedestrian_counts:\n",
    "        print(f\"ğŸš¶ ìµœëŒ€ ë³´í–‰ì ìˆ˜: {max(pedestrian_counts)}ëª…\")\n",
    "        print(f\"ğŸš¶ í‰ê·  ë³´í–‰ì ìˆ˜: {sum(pedestrian_counts)/len(pedestrian_counts):.1f}ëª…\")\n",
    "    \n",
    "    print(f\"ğŸ’¾ ê²°ê³¼ íŒŒì¼: {output_path}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "print(\"âœ… ë©”ì¸ ë¶„ì„ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "444d968a-0970-47be-ab6c-453059a0667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!\n",
      "ğŸ’» ë””ë°”ì´ìŠ¤: cuda\n",
      "ğŸ¯ GPU: NVIDIA GeForce RTX 3090\n",
      "âœ… TrafficCamNet ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!\")\n",
    "\n",
    "# GPU ì„¤ì •\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸ’» ë””ë°”ì´ìŠ¤: {device}\")\n",
    "print(f\"ğŸ¯ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model = detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"âœ… TrafficCamNet ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0426957-5062-4792-a0e8-2d1c9c82619f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë“  í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# í´ë˜ìŠ¤ ì´ë¦„ ë³€í™˜\n",
    "def get_class_name(class_id):\n",
    "    class_names = {\n",
    "        1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle',\n",
    "        6: 'bus', 8: 'truck', 10: 'traffic_light', 13: 'stop_sign'\n",
    "    }\n",
    "    return class_names.get(class_id, f'object_{class_id}')\n",
    "\n",
    "# í”„ë ˆì„ ë¶„ì„ í•¨ìˆ˜\n",
    "def analyze_frame(image, confidence_threshold=0.4):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_tensor)\n",
    "    \n",
    "    scores = predictions[0]['scores'].cpu().numpy()\n",
    "    labels = predictions[0]['labels'].cpu().numpy()\n",
    "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
    "    \n",
    "    vehicles = []\n",
    "    pedestrians = []\n",
    "    infrastructure = []\n",
    "    \n",
    "    VEHICLE_CLASSES = [2, 3, 4, 6, 8]\n",
    "    \n",
    "    for score, label, box in zip(scores, labels, boxes):\n",
    "        if score > confidence_threshold:\n",
    "            obj_info = {\n",
    "                'class_name': get_class_name(label),\n",
    "                'score': score,\n",
    "                'box': box\n",
    "            }\n",
    "            \n",
    "            if label in VEHICLE_CLASSES:\n",
    "                vehicles.append(obj_info)\n",
    "            elif label == 1:\n",
    "                pedestrians.append(obj_info)\n",
    "            elif label in [10, 13]:\n",
    "                infrastructure.append(obj_info)\n",
    "    \n",
    "    return {\n",
    "        'vehicles': vehicles,\n",
    "        'pedestrians': pedestrians,\n",
    "        'infrastructure': infrastructure\n",
    "    }\n",
    "\n",
    "# ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
    "def draw_detections(frame, results):\n",
    "    annotated = frame.copy()\n",
    "    \n",
    "    # ì°¨ëŸ‰ (ë¹¨ê°„ìƒ‰)\n",
    "    for vehicle in results['vehicles']:\n",
    "        box = vehicle['box'].astype(int)\n",
    "        cv2.rectangle(annotated, (box[0], box[1]), (box[2], box[3]), (0, 0, 255), 2)\n",
    "        label = f\"{vehicle['class_name']}: {vehicle['score']:.2f}\"\n",
    "        cv2.putText(annotated, label, (box[0], box[1]-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    \n",
    "    # ë³´í–‰ì (íŒŒë€ìƒ‰)\n",
    "    for person in results['pedestrians']:\n",
    "        box = person['box'].astype(int)\n",
    "        cv2.rectangle(annotated, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 2)\n",
    "        label = f\"Person: {person['score']:.2f}\"\n",
    "        cv2.putText(annotated, label, (box[0], box[1]-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "    # êµí†µ ì¸í”„ë¼ (ì´ˆë¡ìƒ‰)\n",
    "    for infra in results['infrastructure']:\n",
    "        box = infra['box'].astype(int)\n",
    "        cv2.rectangle(annotated, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "        label = f\"{infra['class_name']}: {infra['score']:.2f}\"\n",
    "        cv2.putText(annotated, label, (box[0], box[1]-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    return annotated\n",
    "\n",
    "print(\"âœ… ëª¨ë“  í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "289d2aa6-3885-4209-937c-a78823f1e96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì˜ìƒ ë¶„ì„ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "def analyze_traffic_video():\n",
    "    \"\"\"TrafficCamNet ì˜ìƒ ë¶„ì„\"\"\"\n",
    "    \n",
    "    # ì‚¬ìš©í•  ì˜ìƒ íŒŒì¼ ì°¾ê¸°\n",
    "    video_files = []\n",
    "    for file in os.listdir('.'):\n",
    "        if file.endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "            video_files.append(file)\n",
    "    \n",
    "    if not video_files:\n",
    "        print(\"âŒ ì˜ìƒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        return None\n",
    "    \n",
    "    # ì²« ë²ˆì§¸ ì˜ìƒ íŒŒì¼ ì‚¬ìš©\n",
    "    video_path = video_files[0]\n",
    "    print(f\"ğŸ¯ ì‚¬ìš©í•  ì˜ìƒ: {video_path}\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"âŒ ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}\")\n",
    "        return None\n",
    "    \n",
    "    # ì˜ìƒ ì •ë³´\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"ğŸ“¹ ì˜ìƒ ì •ë³´: {width}x{height}, {fps}fps, {total_frames}í”„ë ˆì„\")\n",
    "    \n",
    "    # ì¶œë ¥ ì˜ìƒ ì„¤ì •\n",
    "    output_path = \"traffic_analysis_result.mp4\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    vehicle_stats = []\n",
    "    pedestrian_stats = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"ğŸš€ TrafficCamNet ë¶„ì„ ì‹œì‘!\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # RGB ë³€í™˜\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # TrafficCamNet ë¶„ì„\n",
    "        results = analyze_frame(frame_rgb)\n",
    "        \n",
    "        # í†µê³„ ìˆ˜ì§‘\n",
    "        vehicles = len(results['vehicles'])\n",
    "        pedestrians = len(results['pedestrians'])\n",
    "        infrastructure = len(results['infrastructure'])\n",
    "        \n",
    "        vehicle_stats.append(vehicles)\n",
    "        pedestrian_stats.append(pedestrians)\n",
    "        \n",
    "        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
    "        annotated_frame = draw_detections(frame, results)\n",
    "        \n",
    "        # ì •ë³´ ì˜¤ë²„ë ˆì´\n",
    "        current_time = frame_count / fps\n",
    "        info_lines = [\n",
    "            f\"Frame: {frame_count}/{total_frames}\",\n",
    "            f\"Time: {current_time:.1f}s\",\n",
    "            f\"Vehicles: {vehicles}\",\n",
    "            f\"Pedestrians: {pedestrians}\",\n",
    "            f\"Infrastructure: {infrastructure}\",\n",
    "            \"RTX 3090 TrafficCamNet\"\n",
    "        ]\n",
    "        \n",
    "        # ë°°ê²½ ë°•ìŠ¤\n",
    "        cv2.rectangle(annotated_frame, (5, 5), (280, 160), (0, 0, 0), -1)\n",
    "        \n",
    "        # ì •ë³´ í…ìŠ¤íŠ¸\n",
    "        y_pos = 25\n",
    "        for line in info_lines:\n",
    "            cv2.putText(annotated_frame, line, (10, y_pos), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            y_pos += 22\n",
    "        \n",
    "        # ì¶œë ¥ ì˜ìƒì— ì“°ê¸°\n",
    "        out.write(annotated_frame)\n",
    "        \n",
    "        # ì§„í–‰ ìƒí™© (10í”„ë ˆì„ë§ˆë‹¤)\n",
    "        if frame_count % 10 == 0:\n",
    "            progress = frame_count / total_frames * 100\n",
    "            elapsed = time.time() - start_time\n",
    "            fps_current = frame_count / elapsed if elapsed > 0 else 0\n",
    "            \n",
    "            print(f\"ì§„í–‰ë¥ : {progress:5.1f}% | \"\n",
    "                  f\"ì°¨ëŸ‰: {vehicles:2d}ëŒ€ | \"\n",
    "                  f\"ë³´í–‰ì: {pedestrians:2d}ëª… | \"\n",
    "                  f\"ì†ë„: {fps_current:5.1f} FPS\")\n",
    "    \n",
    "    # ì •ë¦¬\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"ğŸ¬ TrafficCamNet ë¶„ì„ ì™„ë£Œ!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {total_time:.1f}ì´ˆ\")\n",
    "    print(f\"ğŸ”¥ í‰ê·  ì†ë„: {frame_count/total_time:.1f} FPS\")\n",
    "    \n",
    "    if vehicle_stats:\n",
    "        print(f\"ğŸš— ìµœëŒ€ ì°¨ëŸ‰: {max(vehicle_stats)}ëŒ€\")\n",
    "        print(f\"ğŸš— í‰ê·  ì°¨ëŸ‰: {sum(vehicle_stats)/len(vehicle_stats):.1f}ëŒ€\")\n",
    "    \n",
    "    if pedestrian_stats:\n",
    "        print(f\"ğŸš¶ ìµœëŒ€ ë³´í–‰ì: {max(pedestrian_stats)}ëª…\")\n",
    "        print(f\"ğŸš¶ í‰ê·  ë³´í–‰ì: {sum(pedestrian_stats)/len(pedestrian_stats):.1f}ëª…\")\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        output_size = os.path.getsize(output_path) / (1024*1024)\n",
    "        print(f\"ğŸ’¾ ê²°ê³¼ íŒŒì¼: {output_path} ({output_size:.1f} MB)\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "print(\"âœ… ì˜ìƒ ë¶„ì„ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbcc079b-9459-4add-b044-2d18252fdc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ì‚¬ìš©í•  ì˜ìƒ: traffic_short.mp4\n",
      "ğŸ“¹ ì˜ìƒ ì •ë³´: 360x640, 30fps, 372í”„ë ˆì„\n",
      "ğŸš€ TrafficCamNet ë¶„ì„ ì‹œì‘!\n",
      "==================================================\n",
      "ì§„í–‰ë¥ :   2.7% | ì°¨ëŸ‰: 21ëŒ€ | ë³´í–‰ì: 23ëª… | ì†ë„:   8.9 FPS\n",
      "ì§„í–‰ë¥ :   5.4% | ì°¨ëŸ‰: 15ëŒ€ | ë³´í–‰ì: 25ëª… | ì†ë„:  11.2 FPS\n",
      "ì§„í–‰ë¥ :   8.1% | ì°¨ëŸ‰: 12ëŒ€ | ë³´í–‰ì: 24ëª… | ì†ë„:  11.6 FPS\n",
      "ì§„í–‰ë¥ :  10.8% | ì°¨ëŸ‰: 16ëŒ€ | ë³´í–‰ì: 23ëª… | ì†ë„:  12.2 FPS\n",
      "ì§„í–‰ë¥ :  13.4% | ì°¨ëŸ‰:  8ëŒ€ | ë³´í–‰ì: 24ëª… | ì†ë„:  12.6 FPS\n",
      "ì§„í–‰ë¥ :  16.1% | ì°¨ëŸ‰: 11ëŒ€ | ë³´í–‰ì: 24ëª… | ì†ë„:  13.1 FPS\n",
      "ì§„í–‰ë¥ :  18.8% | ì°¨ëŸ‰: 10ëŒ€ | ë³´í–‰ì: 18ëª… | ì†ë„:  13.3 FPS\n",
      "ì§„í–‰ë¥ :  21.5% | ì°¨ëŸ‰:  6ëŒ€ | ë³´í–‰ì: 20ëª… | ì†ë„:  13.4 FPS\n",
      "ì§„í–‰ë¥ :  24.2% | ì°¨ëŸ‰: 15ëŒ€ | ë³´í–‰ì: 24ëª… | ì†ë„:  13.6 FPS\n",
      "ì§„í–‰ë¥ :  26.9% | ì°¨ëŸ‰: 16ëŒ€ | ë³´í–‰ì: 20ëª… | ì†ë„:  13.7 FPS\n",
      "ì§„í–‰ë¥ :  29.6% | ì°¨ëŸ‰: 11ëŒ€ | ë³´í–‰ì: 18ëª… | ì†ë„:  13.8 FPS\n",
      "ì§„í–‰ë¥ :  32.3% | ì°¨ëŸ‰: 12ëŒ€ | ë³´í–‰ì: 19ëª… | ì†ë„:  13.9 FPS\n",
      "ì§„í–‰ë¥ :  34.9% | ì°¨ëŸ‰:  8ëŒ€ | ë³´í–‰ì: 21ëª… | ì†ë„:  13.9 FPS\n",
      "ì§„í–‰ë¥ :  37.6% | ì°¨ëŸ‰: 21ëŒ€ | ë³´í–‰ì: 26ëª… | ì†ë„:  14.0 FPS\n",
      "ì§„í–‰ë¥ :  40.3% | ì°¨ëŸ‰: 12ëŒ€ | ë³´í–‰ì: 18ëª… | ì†ë„:  14.1 FPS\n",
      "ì§„í–‰ë¥ :  43.0% | ì°¨ëŸ‰: 12ëŒ€ | ë³´í–‰ì: 14ëª… | ì†ë„:  14.1 FPS\n",
      "ì§„í–‰ë¥ :  45.7% | ì°¨ëŸ‰:  9ëŒ€ | ë³´í–‰ì: 10ëª… | ì†ë„:  14.1 FPS\n",
      "ì§„í–‰ë¥ :  48.4% | ì°¨ëŸ‰:  7ëŒ€ | ë³´í–‰ì: 14ëª… | ì†ë„:  14.2 FPS\n",
      "ì§„í–‰ë¥ :  51.1% | ì°¨ëŸ‰: 16ëŒ€ | ë³´í–‰ì: 14ëª… | ì†ë„:  14.2 FPS\n",
      "ì§„í–‰ë¥ :  53.8% | ì°¨ëŸ‰:  9ëŒ€ | ë³´í–‰ì: 15ëª… | ì†ë„:  14.2 FPS\n",
      "ì§„í–‰ë¥ :  56.5% | ì°¨ëŸ‰:  7ëŒ€ | ë³´í–‰ì: 20ëª… | ì†ë„:  14.2 FPS\n",
      "ì§„í–‰ë¥ :  59.1% | ì°¨ëŸ‰:  5ëŒ€ | ë³´í–‰ì: 13ëª… | ì†ë„:  14.1 FPS\n",
      "ì§„í–‰ë¥ :  61.8% | ì°¨ëŸ‰: 11ëŒ€ | ë³´í–‰ì: 15ëª… | ì†ë„:  14.1 FPS\n",
      "ì§„í–‰ë¥ :  64.5% | ì°¨ëŸ‰:  9ëŒ€ | ë³´í–‰ì: 20ëª… | ì†ë„:  14.1 FPS\n",
      "ì§„í–‰ë¥ :  67.2% | ì°¨ëŸ‰:  7ëŒ€ | ë³´í–‰ì: 30ëª… | ì†ë„:  14.1 FPS\n",
      "ì§„í–‰ë¥ :  69.9% | ì°¨ëŸ‰:  8ëŒ€ | ë³´í–‰ì: 16ëª… | ì†ë„:  14.2 FPS\n",
      "ì§„í–‰ë¥ :  72.6% | ì°¨ëŸ‰:  8ëŒ€ | ë³´í–‰ì: 24ëª… | ì†ë„:  14.2 FPS\n",
      "ì§„í–‰ë¥ :  75.3% | ì°¨ëŸ‰:  5ëŒ€ | ë³´í–‰ì: 24ëª… | ì†ë„:  14.2 FPS\n",
      "ì§„í–‰ë¥ :  78.0% | ì°¨ëŸ‰:  6ëŒ€ | ë³´í–‰ì: 21ëª… | ì†ë„:  14.2 FPS\n",
      "ì§„í–‰ë¥ :  80.6% | ì°¨ëŸ‰:  3ëŒ€ | ë³´í–‰ì: 16ëª… | ì†ë„:  14.2 FPS\n",
      "ì§„í–‰ë¥ :  83.3% | ì°¨ëŸ‰:  9ëŒ€ | ë³´í–‰ì: 30ëª… | ì†ë„:  14.2 FPS\n",
      "ì§„í–‰ë¥ :  86.0% | ì°¨ëŸ‰:  6ëŒ€ | ë³´í–‰ì: 24ëª… | ì†ë„:  14.3 FPS\n",
      "ì§„í–‰ë¥ :  88.7% | ì°¨ëŸ‰:  5ëŒ€ | ë³´í–‰ì: 36ëª… | ì†ë„:  14.3 FPS\n",
      "ì§„í–‰ë¥ :  91.4% | ì°¨ëŸ‰:  7ëŒ€ | ë³´í–‰ì: 27ëª… | ì†ë„:  14.3 FPS\n",
      "ì§„í–‰ë¥ :  94.1% | ì°¨ëŸ‰:  8ëŒ€ | ë³´í–‰ì: 24ëª… | ì†ë„:  14.3 FPS\n",
      "ì§„í–‰ë¥ :  96.8% | ì°¨ëŸ‰: 10ëŒ€ | ë³´í–‰ì: 24ëª… | ì†ë„:  14.3 FPS\n",
      "ì§„í–‰ë¥ :  99.5% | ì°¨ëŸ‰:  3ëŒ€ | ë³´í–‰ì: 20ëª… | ì†ë„:  14.3 FPS\n",
      "\n",
      "==================================================\n",
      "ğŸ¬ TrafficCamNet ë¶„ì„ ì™„ë£Œ!\n",
      "==================================================\n",
      "â±ï¸ ì²˜ë¦¬ ì‹œê°„: 26.0ì´ˆ\n",
      "ğŸ”¥ í‰ê·  ì†ë„: 14.3 FPS\n",
      "ğŸš— ìµœëŒ€ ì°¨ëŸ‰: 21ëŒ€\n",
      "ğŸš— í‰ê·  ì°¨ëŸ‰: 9.8ëŒ€\n",
      "ğŸš¶ ìµœëŒ€ ë³´í–‰ì: 36ëª…\n",
      "ğŸš¶ í‰ê·  ë³´í–‰ì: 21.4ëª…\n",
      "ğŸ’¾ ê²°ê³¼ íŒŒì¼: traffic_analysis_result.mp4 (20.7 MB)\n",
      "\n",
      "âœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ!\n",
      "ğŸ“¹ ê²°ê³¼ ì˜ìƒ: traffic_analysis_result.mp4\n"
     ]
    }
   ],
   "source": [
    "# TrafficCamNet ì˜ìƒ ë¶„ì„ ì‹¤í–‰\n",
    "result_video = analyze_traffic_video()\n",
    "\n",
    "if result_video:\n",
    "    print(f\"\\nâœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“¹ ê²°ê³¼ ì˜ìƒ: {result_video}\")\n",
    "else:\n",
    "    print(\"âŒ ë¶„ì„ ì‹¤íŒ¨!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b84c7-f3c9-458e-b0b9-115c69ebe07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
